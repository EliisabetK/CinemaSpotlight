import requests
from bs4 import BeautifulSoup
import psycopg2
from psycopg2 import sql
from datetime import datetime
import json

# Function to convert movie length like '2h15' to minutes
def convert_runtime_to_minutes(runtime):
    if 'h' in runtime and 'min' in runtime:
        hours, minutes = map(int, runtime.replace('h', '').replace('min', '').split(' '))
        return hours * 60 + minutes
    elif 'h' in runtime:
        return int(runtime.replace('h', '')) * 60
    elif 'min' in runtime:
        return int(runtime.replace('min', ''))
    else:
        return None

# Function to trim the summary to 1000 characters if necessary
def trim_summary(summary):
    return summary[:1000] if summary else None

# Function to process image links
def process_image_link(cover):
    # Add "http://" to the beginning of the image link
    cover = "http://" + cover

    # Remove unnecessary parts from the image link
    cover = cover.replace('//images.markus.live/', '').split('?')[0]

    # Remove everything that comes after .jpg
    cover = cover.split('.jpg')[0] + '.jpg'

    return cover

# Function to get movie details from TMDB API
def get_movie_details_from_tmdb(title, api_key):
    base_url = f'https://api.themoviedb.org/3/search/movie'
    params = {'api_key': api_key, 'query': title}
    
    response = requests.get(base_url, params=params)
    
    if response.status_code == 200:
        movie_details = json.loads(response.text)
        if movie_details['results']:
            return movie_details['results'][0]  # Return the first result
    return None

# Function to scrape movie data from the Apollo page
def scrape_movie_data(url, api_key):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    movies = []

    # Replace these selectors with the actual HTML elements from the target website
    movie_elements = soup.select('.movie-card')

    for movie_element in movie_elements:
        # Extracting data
        title_element = movie_element.select_one('.movie-card__title a')
        cover_element = movie_element.select_one('.image__img')

        # Exclude movies with "OPERA" or "BALLET" in the title
        if 'OPERA' in title_element.text.upper() or 'BALLET' in title_element.text.upper():
            continue
        
        title = title_element.text.strip()
        title = title.replace('Cinema Classics: ', '')  # Remove prefix if it exists

        # Extract details from the movie details page
        details_url = title_element['href']
        details_response = requests.get(details_url)
        details_soup = BeautifulSoup(details_response.text, 'html.parser')

        # Use find_next_sibling to locate the next sibling element after the specified key element
        director_element = details_soup.find('p', string='Director')
        director = director_element.find_next_sibling('p').text.strip() if director_element else None

        runtime_element = details_soup.find('p', string='Run time')
        runtime = runtime_element.find_next_sibling('p').text.strip() if runtime_element else None

        releasedate_element = details_soup.find('p', string='In Cinemas')
        releasedate_str = releasedate_element.find_next_sibling('p').text.strip() if releasedate_element else None

        # Adjust the date format
        releasedate = datetime.strptime(releasedate_str, '%m/%d/%Y') if releasedate_str else None

        summary_element = details_soup.select_one('.movie-details__description .text')
        summary = trim_summary(summary_element.text.strip()) if summary_element else None

        link = title_element['href']
        cover = cover_element['data-srcset'].split(' ')[-2]  # Extracting the last URL in the srcset

        # Process the image link
        cover = process_image_link(cover)

        # Convert the runtime to minutes
        runtime_in_minutes = convert_runtime_to_minutes(runtime)

        tmdb_movie_details = get_movie_details_from_tmdb(title, api_key)

        if tmdb_movie_details is not None and 'vote_average' in tmdb_movie_details:
            score = tmdb_movie_details['vote_average']
        else:
            score = None

        movies.append({
            'title': title,
            'link': link,
            'cover': cover,
            'director': director,
            'runtime': runtime_in_minutes,
            'releasedate': releasedate,
            'tmdb': score,
            'summary': summary,
        })
        print(f"Title: {title}, Director: {director}, Runtime: {runtime_in_minutes} minutes")

    return movies


# Function to save data to PostgreSQL database
def save_to_database(movies):
    conn = psycopg2.connect(
        host="localhost",
        database="homework4",
        user="postgres",
        password="eliisabet"
    )
    cursor = conn.cursor()

    # Create a table if it doesn't exist
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS movies (
            id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
            name VARCHAR(200) NOT NULL UNIQUE,
            director VARCHAR(200),
            length INTEGER,
            releasedate timestamp,
            tmdb DECIMAL(3, 1),
            summary TEXT,
            photo VARCHAR(1000)
        )
    ''')

    # Insert data into the table with ON CONFLICT clause, only if director is not None
    for movie in movies:
        if movie['director'] is not None:
            cursor.execute(sql.SQL('''
                INSERT INTO movies (name, director, length, releasedate, tmdb,summary, photo)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (name) DO UPDATE
                SET director = EXCLUDED.director,
                    length = EXCLUDED.length,
                    releasedate = EXCLUDED.releasedate,
                    tmdb = EXCLUDED.tmdb,
                    summary = EXCLUDED.summary,
                    photo = EXCLUDED.photo
            '''), (movie['title'], movie['director'], movie['runtime'], movie['releasedate'], movie['tmdb'], movie['summary'], movie['cover']))

    conn.commit()
    conn.close()

api_key = 'de150413238cb1ec0252f5c6374f3691'
url = 'https://www.apollokino.ee/eng/movies?fromLang=1001'
movies_data = scrape_movie_data(url, api_key)
save_to_database(movies_data)
